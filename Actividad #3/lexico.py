# -*- coding: utf-8 -*-
"""Lexico

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vLHKQxcjFXfqT0bkGLQP_B4jxnyG2AD3
"""

import re

class TokenType:
    IDENTIFIER = "Identificador"
    INTEGER = "Entero"
    FLOAT = "Real"
    STRING = "Cadena"
    KEYWORD = "Palabra Reservada"
    ARITHMETIC_OPERATOR = "Operador Aritmético"
    LOGICAL_OPERATOR = "Operador Lógico"
    PARENTHESIS = "Paréntesis"
    KEYS = "Llaves"
    UNKNOWN = "Desconocido"

class Token:
    def __init__(self, type, value):
        self.type = type
        self.value = value

class Lexer:
    def __init__(self, input):
        self.input = input
        self.position = 0

    def get_next_token(self):
        if self.position >= len(self.input):
            return Token(TokenType.UNKNOWN, "")

        current_char = self.input[self.position]

        if re.match(r'\d', current_char):
            return self.get_number_token()
        elif re.match(r'[a-zA-Z]', current_char):
            return self.get_identifier_or_keyword_token()
        elif current_char in ['+', '-', '*', '/', '=', '%']:
            return self.get_arithmetic_operator_token()
        elif current_char in ['&', '|']:
            return self.get_logical_operator_token()
        elif current_char == '.':
            return self.get_float_token()
        elif current_char == '"':
            return self.get_string_token()
        elif current_char in ['(', ')']:
            return self.get_parenthesis_token()
        elif current_char in ['{', '}']:
            return self.get_keys_token()
        else:
            self.position += 1
            return Token(TokenType.UNKNOWN, current_char)

    def get_number_token(self):
        number = ''
        while self.position < len(self.input) and (re.match(r'\d', self.input[self.position]) or self.input[self.position] == '.'):
            number += self.input[self.position]
            self.position += 1

        return Token(TokenType.INTEGER if '.' not in number else TokenType.FLOAT, number)

    def get_identifier_or_keyword_token(self):
        identifier = ''
        while self.position < len(self.input) and re.match(r'\w', self.input[self.position]):
            identifier += self.input[self.position]
            self.position += 1

        if identifier in ['int', 'float', 'void', 'if', 'while', 'return', 'else']:
            return Token(TokenType.KEYWORD, identifier)
        else:
            return Token(TokenType.IDENTIFIER, identifier)

    def get_arithmetic_operator_token(self):
        op = self.input[self.position]
        self.position += 1
        return Token(TokenType.ARITHMETIC_OPERATOR, op)

    def get_logical_operator_token(self):
        op = self.input[self.position]
        self.position += 1
        if self.position < len(self.input) and self.input[self.position] == op:
            op += self.input[self.position]
            self.position += 1
        return Token(TokenType.LOGICAL_OPERATOR, op)

    def get_float_token(self):
        number = ''
        while self.position < len(self.input) and (re.match(r'\d', self.input[self.position]) or self.input[self.position] == '.'):
            number += self.input[self.position]
            self.position += 1

        return Token(TokenType.FLOAT, number)

    def get_string_token(self):
        self.position += 1  # Skip the opening double quote
        string_value = ''
        while self.position < len(self.input) and self.input[self.position] != '"':
            string_value += self.input[self.position]
            self.position += 1

        if self.position < len(self.input) and self.input[self.position] == '"':
            self.position += 1  # Skip the closing double quote

        return Token(TokenType.STRING, string_value)

    def get_parenthesis_token(self):
        parenthesis = self.input[self.position]
        self.position += 1
        return Token(TokenType.PARENTHESIS, parenthesis)

    def get_keys_token(self):
        keys = self.input[self.position]
        self.position += 1
        return Token(TokenType.KEYS, keys)

def main():
    expression = input("Ingrese la cadena: ")
    lexer = Lexer(expression)
    tokens = []

    token = lexer.get_next_token()
    while token.type != TokenType.UNKNOWN:
        tokens.append(token)
        token = lexer.get_next_token()

    # Imprimir tokens
    for t in tokens:
        print(f"Tipo: {t.type}, Valor: {t.value}")


if __name__ == "__main__":
    main()